
![[Pasted image 20250216194841.png]]

![[Pasted image 20250216235308.png]]
### 1. Lexical Analysis
- takes lexemes as input and generates tokens of the form '<token-name, attribute-value>'
- position = initial + rate * 60
	![[Pasted image 20250216234920.png]]
- ![[Pasted image 20250216184628.png]]
### 2. Syntax Analysis
- uses the first components of the tokens produced by lexical analyzer to create a tree intermediate representation that depicts the grammar of the token stream
- syntax tree where each node is operation and children are the arguments of the operations
- ![[Pasted image 20250216235250.png]]

### 3. Semantic Analysis
- uses syntax tree and info in symbol table to check the semantic consistency with language definition
	type checking : ensures operations performed on compatible data types i.e, no int + string
	variable declaration : 
	function calls :
	consistency with language rules :
- ![[Pasted image 20250217002705.png]]
